{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYPD Allegations\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the outcome of an allegation (might need to feature engineer your output column).\n",
    "    * Predict the complainant or officer ethnicity.\n",
    "    * Predict the amount of time between the month received vs month closed (difference of the two columns).\n",
    "    * Predict the rank of the officer.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "The problem we are trying to predict with this NYPD dataset is to find out whether a complaintant is going to get a successful outcome from their allegation. A successful outcome is defined as a complaintant being successful in getting a substantiated result from the governing board, which accepts that the officer did have misconduct. We will use a Decision Tree Classifier to classify the data and use the F1 score as the evaluation metric. Additionally, we will use our cleaned dataset from Project 3 to get more consistent data.\n",
    "\n",
    "### Baseline Model\n",
    "The Baseline Model that we created utilized categorical columns relating only to the alledged officer because the outcome of an allegation might depend on the type of officer involved in a case. Four of these columns consist of nominal data while none are ordinal or quantitative. We One-Hot Encoded these columns into a Column Transformer and then passed them into the default Decision Tree Classifier model. After training this model and testing it using seperate testing data, the calculated F1 score ended up being `0.24049151550614395` which is not a very good score as F1 score is a value between zero and one where 1 is a good score and 0 is a bad score. The reason why this score is bad might be because we did not use any columns relating to the alleged victim or any numerical data.\n",
    "\n",
    "### Final Model\n",
    "In the Final Model that we created, we feature-engineered two columns; `is_white` and `binned_age`. `is_white` is a binarizer that checks if an officer is white or not and sets values as 1 or 0 respectively. This is useful because in Project 3 we determined that there is a difference between the ethnicity of an officer and the time it takes to get a response for an allegation. Therefore, we assumed that there would also be differences between the ethnicity of an officer and the chance of getting a successful outcome from an allegation. `binned_age` is a transformer which bins the ages into sets of 5 for more accurate average age representation by generalizing the noise in data. This would be a good way of incorporating numerical data to the model. We also included categorical columns about the alleged victim because certain factors such as specific ethnicities or more severe allegations would be more likely to lead to a successful outcome. Additionally, we used a grid search to find the best parameters for the Decision Tree Classifier model. The best parameters ended up being `max_depth=550`, `min_samples_split=10`, and `min_samples_leaf=1 (default)`.\n",
    "We decided to stick with using a Decision Tree Classifier because the dataset we are dealing with uses mostly categorical data, which is better for classification than regression. The F1 score of the Final Model ended up being `0.3938630638882528`. Although this Final Model did not improve the F1 score by a massive amount compared to the Baseline Model, it shows a significant improvement in the effectiveness of the Final Model, which shows how impactful optimizing the features and adding relevant features can be. \n",
    "\n",
    "### Fairness Evaluation\n",
    "In order to judge the \"fairness\" of our model, we focused on whether or not the model was fair based on the race of the officer (we narrowed this down to two categories: white and nonwhite. We tried to determine if our model is equally accurate for predicting the outcome of complaints filed against white officers and nonwhite officers. In order to justify this, we used the accuracy parity. If the model is biased towards one of these, that could suggest some sort of racial implications that would make our model \"unfair\", such as a potential discrepancy in our sample population or other forms of racial bias.\n",
    "\n",
    "**Null Hypothesis**: \n",
    "Our biased because it successfully predicts the outcome of a complaint filed against white officers and nonwhite officers at an equal rate. \n",
    "    \n",
    "**Alternative Hypothesis**:\n",
    "Our model successfully predicts the outcome of a complaint filed against white officers at a higher rate than the outcome of complaints filed against nonwhite officers\n",
    "\n",
    "**Threshold**: 0.05\n",
    "\n",
    "According to the pvalue, which is 0.521, our result is not statistically significant. We cannot Reject the Null Hypothesis. This means that our model is at least fair based on our metric of accuracy parity. As well as that our model successfully predicts the outcome of a complaint filed against officers regardless of whether they are white or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complaints = pd.read_csv('CCRB-Complaint-Data_202007271729/allegations_202007271729.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and EDA (From Project 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing \"Unknown\", and \"Refused\" to np.nan in 'complainant_ethnicity' column and changing \"Not described\" to np.nan in 'complainant_gender' column. Were changing \"Refused\" to np.nan because the questons we are asking do not use the refusal information, so it is equivalent to being NaN for us. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints['complainant_gender'] = complaints['complainant_gender'].replace({'Not described': np.nan})\n",
    "complaints['complainant_ethnicity'] = complaints['complainant_ethnicity'].replace({'Unknown':np.nan, 'Refused': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the year_received and year_closed date columns into two approximate datetime columns. Since we are not provided a day for these complaints, we are assuming that they all start on the first of the month. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = np.ones(complaints.shape[0])\n",
    "approx_start = complaints[['year_received', 'month_received']].assign(day_received = days)\n",
    "approx_start = pd.to_datetime(dict(year=approx_start.year_received, \n",
    "                                   month=approx_start.month_received, \n",
    "                                   day=approx_start.day_received))\n",
    "\n",
    "approx_end = complaints[['year_closed', 'month_closed']].assign(day_closed = days)\n",
    "approx_end = pd.to_datetime(dict(year=approx_end.year_closed, \n",
    "                                   month=approx_end.month_closed, \n",
    "                                   day=approx_end.day_closed))\n",
    "\n",
    "complaints = complaints.drop(columns = ['year_closed', 'month_closed', 'year_received'])\n",
    "complaints = complaints.assign(approx_start = approx_start, approx_end = approx_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an approximate duration column which is the time delta between the date received and date closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_duration = complaints['approx_end'] - complaints['approx_start']\n",
    "complaints = complaints.assign(approx_duration = approx_duration.dt.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a column where the value is True if the complaintant was successful in getting a substantiated result from the governing board and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints['complaint_successful'] = complaints['board_disposition'].apply(lambda x: True if x.split(' ')[0] == 'Substantiated' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change precinct column values to string because it is a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a column where the value is True if the Police Officer's Ethnicity in the complaint is White and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "complaints['officer_is_white'] = complaints['mos_ethnicity'].apply(lambda x: 'Yes' if x == 'White' else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints['precinct'] = complaints['precinct'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dropping all unnessesary columns such as names, and id's that are not relevant to our questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shield_no</th>\n",
       "      <th>month_received</th>\n",
       "      <th>command_at_incident</th>\n",
       "      <th>rank_incident</th>\n",
       "      <th>mos_ethnicity</th>\n",
       "      <th>mos_gender</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>allegation</th>\n",
       "      <th>precinct</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>outcome_description</th>\n",
       "      <th>approx_duration</th>\n",
       "      <th>complaint_successful</th>\n",
       "      <th>officer_is_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8409</td>\n",
       "      <td>7</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>305</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5952</td>\n",
       "      <td>11</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Action</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>274</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5952</td>\n",
       "      <td>11</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Offensive Language</td>\n",
       "      <td>Race</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>274</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5952</td>\n",
       "      <td>7</td>\n",
       "      <td>PBBS</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Question</td>\n",
       "      <td>67.0</td>\n",
       "      <td>PD suspected C/V of violation/crime - street</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>427</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24058</td>\n",
       "      <td>8</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>Police Officer</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Force</td>\n",
       "      <td>Physical force</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Report-dispute</td>\n",
       "      <td>Arrest - other violation/crime</td>\n",
       "      <td>184</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shield_no  month_received command_at_incident   rank_incident  \\\n",
       "0       8409               7             078 PCT  Police Officer   \n",
       "1       5952              11                PBBS  Police Officer   \n",
       "2       5952              11                PBBS  Police Officer   \n",
       "3       5952               7                PBBS  Police Officer   \n",
       "4      24058               8             078 PCT  Police Officer   \n",
       "\n",
       "  mos_ethnicity mos_gender  mos_age_incident complainant_ethnicity  \\\n",
       "0      Hispanic          M                32                 Black   \n",
       "1         White          M                24                 Black   \n",
       "2         White          M                24                 Black   \n",
       "3         White          M                25                 Black   \n",
       "4      Hispanic          F                39                   NaN   \n",
       "\n",
       "  complainant_gender  complainant_age_incident           fado_type  \\\n",
       "0             Female                      38.0  Abuse of Authority   \n",
       "1               Male                      26.0         Discourtesy   \n",
       "2               Male                      26.0  Offensive Language   \n",
       "3               Male                      45.0  Abuse of Authority   \n",
       "4                NaN                      16.0               Force   \n",
       "\n",
       "                     allegation precinct  \\\n",
       "0  Failure to provide RTKA card     78.0   \n",
       "1                        Action     67.0   \n",
       "2                          Race     67.0   \n",
       "3                      Question     67.0   \n",
       "4                Physical force     67.0   \n",
       "\n",
       "                                 contact_reason  \\\n",
       "0                       Report-domestic dispute   \n",
       "1                              Moving violation   \n",
       "2                              Moving violation   \n",
       "3  PD suspected C/V of violation/crime - street   \n",
       "4                                Report-dispute   \n",
       "\n",
       "                outcome_description  approx_duration  complaint_successful  \\\n",
       "0  No arrest made or summons issued              305                  True   \n",
       "1   Moving violation summons issued              274                  True   \n",
       "2   Moving violation summons issued              274                  True   \n",
       "3  No arrest made or summons issued              427                  True   \n",
       "4    Arrest - other violation/crime              184                  True   \n",
       "\n",
       "  officer_is_white  \n",
       "0               No  \n",
       "1              Yes  \n",
       "2              Yes  \n",
       "3              Yes  \n",
       "4               No  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints = complaints.drop(columns = ['first_name', 'last_name',  \n",
    "                           'rank_abbrev_now', 'rank_now', 'board_disposition',\n",
    "                           'rank_abbrev_incident', 'command_now',\n",
    "                           'unique_mos_id', 'complaint_id',\n",
    "                           'approx_start', 'approx_end'])\n",
    "complaints.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24014022787028927"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#Get Data and Target Value\n",
    "X = complaints.drop('complaint_successful', axis=1)\n",
    "y = complaints['complaint_successful']\n",
    "\n",
    "#generate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=420)\n",
    "\n",
    "#OneHotEncode Pipeline\n",
    "baseline_cats = [\"mos_ethnicity\", \"rank_incident\", \"shield_no\", \"fado_type\"]\n",
    "onehotpl = Pipeline(steps=[\n",
    "    (\"One-hot\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Column Transformer to add OneHotEncoder to specified categorical columns\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehot\", onehotpl, baseline_cats)\n",
    "],remainder='drop')\n",
    "\n",
    "#General pipeline to utilize ColumnTransformer and pass it to a DecisionTreeClassifier\n",
    "baselinepl = Pipeline(steps=[\n",
    "    (\"transform\", ct),(\"dtc\", DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "#Fit and Predict on General Pipeline\n",
    "baselinepl.fit(X_train,y_train)\n",
    "preds = baselinepl.predict(X_test)\n",
    "\n",
    "#F1 Score\n",
    "metrics.f1_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering an is_white column that checks if an officer is white or not\n",
    "complaints['is_white'] = complaints['mos_ethnicity'].apply(lambda x: 1 if x == 'White' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering a binned_age column which bins the ages into sets of 5 for more accurate modeling\n",
    "complaints['binned_age'] = complaints['mos_age_incident'].apply(lambda x: 5 * (x//5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3957268927078495"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#Get Data and Target Value\n",
    "X = complaints.drop('complaint_successful', axis=1)\n",
    "y = complaints['complaint_successful']\n",
    "\n",
    "#generate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=420)\n",
    "\n",
    "#range of values to perform grid search on\n",
    "grid_search_params = {\n",
    "    'max_depth': np.arange(500, 600, 10),\n",
    "    'min_samples_split': np.arange(10, 20, 2),\n",
    "    'min_samples_leaf': [1, 2, 6, 10]\n",
    "}\n",
    "\n",
    "#grid search on DecisionTreeClassifier with 5 cross folds and F1 score as metric\n",
    "grid_search_clf = GridSearchCV(DecisionTreeClassifier(), grid_search_params, cv = 5, scoring = 'f1')\n",
    "\n",
    "final_cats = [\"rank_incident\", \"shield_no\",\n",
    "                 \"allegation\",\"contact_reason\", \n",
    "                 \"mos_gender\",'command_at_incident', \n",
    "                 'complainant_ethnicity',\n",
    "                 'precinct']\n",
    "\n",
    "pass_col = ['is_white', 'binned_age']\n",
    "\n",
    "\n",
    "#OneHotEncode Pipeline\n",
    "onehotpl = Pipeline(steps=[\n",
    "    (\"One-hot\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Column Transformer to apply OneHotEncoder to categorical columns and have feature engineered columns as a passthrough\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehot\", onehotpl, final_cats),\n",
    "    ('pass', FunctionTransformer(lambda x: x), pass_col)\n",
    "], remainder='drop')\n",
    "\n",
    "\n",
    "#General pipeline to utilize ColumnTransformer and pass it to a DecisionTreeClassifier optimized with Grid Search\n",
    "final_pl = Pipeline(steps=[\n",
    "    (\"transform\", ct),\n",
    "    (\"classify\", grid_search_clf)\n",
    "])\n",
    "\n",
    "#Fit and Predict on General Pipeline\n",
    "final_pl.fit(X_train,y_train)\n",
    "preds = final_pl.predict(X_test)\n",
    "\n",
    "#F1 Score\n",
    "metrics.f1_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=520, min_samples_split=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimators for DecisionTreeClassifier\n",
    "grid_search_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "#### Below is a permutation test for accuracy pairty\n",
    "#Create test,training set and observed value\n",
    "X = complaints.drop('complaint_successful', axis=1)\n",
    "y = complaints.complaint_successful\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X,y, test_size=0.3)\n",
    "baselinepl.fit(X_tr,y_tr)\n",
    "preds = final_pl.predict(X_ts)\n",
    "results = X_ts\n",
    "results['prediction'] = preds\n",
    "results['outcome'] = y_ts\n",
    "results.groupby('is_white').prediction.mean().to_frame()\n",
    "\n",
    "#observed accuracy for permutation test\n",
    "obs = (\n",
    "    results\n",
    "    .groupby('is_white')\n",
    "    .apply(lambda x: metrics.accuracy_score(x.outcome, x.prediction))\n",
    "    .rename('accuracy')\n",
    "    .to_frame()\n",
    "    .diff()\n",
    "    .iloc[-1][0]\n",
    ")\n",
    "metrs = []\n",
    "n = 1000\n",
    "for _ in range(n):\n",
    "    #Generate test Statistic (Absolute difference in  means between accuracy when officer is white vs not white)\n",
    "    s = (\n",
    "        results[['is_white', 'prediction', 'outcome']].assign(is_white=results\n",
    "                                                              .is_white.sample(frac=1.0, replace=False)\n",
    "                                                              .reset_index(drop=True))\n",
    "        .groupby('is_white')\n",
    "        .apply(lambda x: metrics.accuracy_score(x.outcome, x.prediction))\n",
    "        .diff()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    \n",
    "    metrs.append(s)\n",
    "    \n",
    "    \n",
    "#Calculate the p_value     \n",
    "p_value = (metrs <= obs).mean()\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
